#!/usr/bin/env python3
"""
å°ˆé–€ç”¨æ–¼é”åˆ°100%è¨“ç·´æº–ç¢ºç‡çš„è¨“ç·´è…³æœ¬
é€šéä½¿ç”¨æ›´å¤§æ¨¡å‹ã€æ›´å°å­¸ç¿’ç‡ã€æ›´å¤šè¨“ç·´è¼ªæ•¸ä¾†å¯¦ç¾å®Œå…¨éæ“¬åˆ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
from torchvision import datasets, transforms, models
import argparse
import os
import time
import copy
import matplotlib.pyplot as plt
import numpy as np

class OverfitTrainer:
    def __init__(self, data_dir, target_accuracy=1.0):
        self.data_dir = data_dir
        self.target_accuracy = target_accuracy
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        
        print(f"ğŸ¯ ç›®æ¨™è¨“ç·´æº–ç¢ºç‡: {target_accuracy*100:.1f}%")
        print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {self.device}")
        
        # é‡å°éæ“¬åˆçš„æ•¸æ“šè®Šæ›ï¼ˆæ¸›å°‘éš¨æ©Ÿæ€§ï¼‰
        self.data_transforms = {
            'train': transforms.Compose([
                transforms.Resize(256),
                transforms.CenterCrop(224),  # ä½¿ç”¨ä¸­å¿ƒè£å‰ªè€Œééš¨æ©Ÿè£å‰ª
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
            'val': transforms.Compose([
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
        }
        
        self.model = None
        self.optimizer = None
        self.criterion = nn.CrossEntropyLoss()
        self.dataloaders = {}
        self.dataset_sizes = {}
        self.class_names = []
        
    def load_data(self):
        """åŠ è¼‰æ•¸æ“š"""
        print("ğŸ“‚ æ­£åœ¨åŠ è¼‰æ•¸æ“š...")
        
        image_datasets = {x: datasets.ImageFolder(os.path.join(self.data_dir, x),
                                                self.data_transforms[x])
                         for x in ['train', 'val']}
        
        # ä½¿ç”¨è¼ƒå°çš„batch sizeä»¥ç²å¾—æ›´ç²¾ç¢ºçš„æ¢¯åº¦
        self.dataloaders = {x: DataLoader(image_datasets[x], batch_size=8,
                                        shuffle=(x == 'train'), num_workers=4)
                          for x in ['train', 'val']}
        
        self.dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
        self.class_names = image_datasets['train'].classes
        
        print(f"âœ… è¨“ç·´é›†å¤§å°: {self.dataset_sizes['train']}")
        print(f"âœ… é©—è­‰é›†å¤§å°: {self.dataset_sizes['val']}")
        print(f"âœ… é¡åˆ¥: {self.class_names}")
        
    def build_model(self, architecture='resnet50'):
        """æ§‹å»ºæ›´å¤§å®¹é‡çš„æ¨¡å‹"""
        print(f"ğŸ—ï¸ æ­£åœ¨æ§‹å»ºæ¨¡å‹: {architecture}")
        
        if architecture == 'resnet50':
            self.model = models.resnet50(pretrained=True)
            num_ftrs = self.model.fc.in_features
            self.model.fc = nn.Linear(num_ftrs, 2)
        elif architecture == 'resnet101':
            self.model = models.resnet101(pretrained=True)
            num_ftrs = self.model.fc.in_features
            self.model.fc = nn.Linear(num_ftrs, 2)
        elif architecture == 'resnet34':
            self.model = models.resnet34(pretrained=True)
            num_ftrs = self.model.fc.in_features
            self.model.fc = nn.Linear(num_ftrs, 2)
        else:  # resnet18
            self.model = models.resnet18(pretrained=True)
            num_ftrs = self.model.fc.in_features
            self.model.fc = nn.Linear(num_ftrs, 2)
        
        # è§£å‡æ‰€æœ‰å±¤é€²è¡Œè¨“ç·´ï¼ˆä¸å‡çµä»»ä½•å±¤ï¼‰
        for param in self.model.parameters():
            param.requires_grad = True
        
        self.model = self.model.to(self.device)
        
        # ä½¿ç”¨éå¸¸å°çš„å­¸ç¿’ç‡ä»¥å¯¦ç¾ç²¾ç¢ºæ“¬åˆ
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.00001, weight_decay=0.0)
        
        print(f"âœ… æ¨¡å‹å·²æ§‹å»ºï¼Œæ‰€æœ‰å±¤å‡å¯è¨“ç·´")
        
    def train_to_perfection(self, max_epochs=200):
        """è¨“ç·´ç›´åˆ°é”åˆ°ç›®æ¨™æº–ç¢ºç‡"""
        print(f"ğŸš€ é–‹å§‹è¨“ç·´åˆ° {self.target_accuracy*100:.1f}% æº–ç¢ºç‡...")
        print(f"ğŸ”„ æœ€å¤§è¨“ç·´è¼ªæ•¸: {max_epochs}")
        print("=" * 60)
        
        since = time.time()
        best_model_wts = copy.deepcopy(self.model.state_dict())
        best_acc = 0.0
        
        train_losses = []
        val_losses = []
        train_accuracies = []
        val_accuracies = []
        
        epochs_without_improvement = 0
        max_patience = 30
        
        for epoch in range(max_epochs):
            print(f'Epoch {epoch+1}/{max_epochs}')
            print('-' * 40)
            
            # æ¯å€‹epochéƒ½æœ‰è¨“ç·´å’Œé©—è­‰éšæ®µ
            epoch_train_acc = 0.0
            epoch_val_acc = 0.0
            
            for phase in ['train', 'val']:
                if phase == 'train':
                    self.model.train()
                else:
                    self.model.eval()
                
                running_loss = 0.0
                running_corrects = 0
                
                # éæ­·æ•¸æ“š
                for inputs, labels in self.dataloaders[phase]:
                    inputs = inputs.to(self.device)
                    labels = labels.to(self.device)
                    
                    self.optimizer.zero_grad()
                    
                    with torch.set_grad_enabled(phase == 'train'):
                        outputs = self.model(inputs)
                        _, preds = torch.max(outputs, 1)
                        loss = self.criterion(outputs, labels)
                        
                        if phase == 'train':
                            loss.backward()
                            self.optimizer.step()
                    
                    running_loss += loss.item() * inputs.size(0)
                    running_corrects += torch.sum(preds == labels.data)
                
                epoch_loss = running_loss / self.dataset_sizes[phase]
                epoch_acc = running_corrects.double() / self.dataset_sizes[phase]
                
                print(f'{phase} Loss: {epoch_loss:.6f} Acc: {epoch_acc:.4f} ({epoch_acc*100:.2f}%)')
                
                if phase == 'train':
                    train_losses.append(epoch_loss)
                    train_accuracies.append(epoch_acc.cpu().numpy())
                    epoch_train_acc = epoch_acc
                else:
                    val_losses.append(epoch_loss)
                    val_accuracies.append(epoch_acc.cpu().numpy())
                    epoch_val_acc = epoch_acc
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                if phase == 'val' and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    best_model_wts = copy.deepcopy(self.model.state_dict())
                    epochs_without_improvement = 0
                elif phase == 'val':
                    epochs_without_improvement += 1
            
            # æª¢æŸ¥æ˜¯å¦é”åˆ°ç›®æ¨™è¨“ç·´æº–ç¢ºç‡
            if epoch_train_acc >= self.target_accuracy:
                print(f"\nğŸ‰ é”åˆ°ç›®æ¨™è¨“ç·´æº–ç¢ºç‡ {self.target_accuracy*100:.1f}%ï¼")
                print(f"å¯¦éš›è¨“ç·´æº–ç¢ºç‡: {epoch_train_acc*100:.2f}%")
                print(f"åœ¨ç¬¬ {epoch+1} è¼ªé”æˆç›®æ¨™")
                break
            
            # æ—©åœæ©Ÿåˆ¶ï¼ˆä½†ä¸»è¦é—œæ³¨è¨“ç·´æº–ç¢ºç‡ï¼‰
            if epochs_without_improvement >= max_patience:
                print(f"\nâ° é©—è­‰æº–ç¢ºç‡ {max_patience} è¼ªç„¡æ”¹å–„ï¼Œä½†ç¹¼çºŒè¿½æ±‚è¨“ç·´æº–ç¢ºç‡...")
                # ä¸åœæ­¢è¨“ç·´ï¼Œç¹¼çºŒè¿½æ±‚100%è¨“ç·´æº–ç¢ºç‡
            
            print()
        
        time_elapsed = time.time() - since
        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
        print(f'Best val Acc: {best_acc:4f}')
        
        # å¦‚æœæ²’æœ‰é”åˆ°ç›®æ¨™ï¼Œä½¿ç”¨ç•¶å‰æ¨¡å‹
        if epoch_train_acc < self.target_accuracy:
            print(f"âš ï¸ æœªå®Œå…¨é”åˆ°ç›®æ¨™ï¼Œæœ€çµ‚è¨“ç·´æº–ç¢ºç‡: {epoch_train_acc*100:.2f}%")
            self.model.load_state_dict(self.model.state_dict())  # ä½¿ç”¨æœ€å¾Œçš„æ¨¡å‹
        else:
            self.model.load_state_dict(self.model.state_dict())  # ä½¿ç”¨é”æˆç›®æ¨™çš„æ¨¡å‹
        
        # ç¹ªè£½è¨“ç·´æ›²ç·š
        self.plot_training_curves(train_losses, val_losses, train_accuracies, val_accuracies)
        
        return self.model
    
    def plot_training_curves(self, train_losses, val_losses, train_accs, val_accs):
        """ç¹ªè£½è¨“ç·´æ›²ç·š"""
        plt.figure(figsize=(15, 5))
        
        plt.subplot(1, 3, 1)
        plt.plot(train_losses, label='Train Loss', color='blue')
        plt.plot(val_losses, label='Val Loss', color='red')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.title('Training and Validation Loss')
        plt.grid(True)
        
        plt.subplot(1, 3, 2)
        plt.plot(train_accs, label='Train Acc', color='blue')
        plt.plot(val_accs, label='Val Acc', color='red')
        plt.axhline(y=self.target_accuracy, color='green', linestyle='--', label=f'Target ({self.target_accuracy*100:.0f}%)')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        plt.title('Training and Validation Accuracy')
        plt.grid(True)
        
        plt.subplot(1, 3, 3)
        # æ”¾å¤§è¨“ç·´æº–ç¢ºç‡æ›²ç·š
        plt.plot(train_accs, label='Train Acc', color='blue', linewidth=2)
        plt.axhline(y=self.target_accuracy, color='green', linestyle='--', label=f'Target ({self.target_accuracy*100:.0f}%)')
        plt.xlabel('Epoch')
        plt.ylabel('Training Accuracy')
        plt.ylim(0.9, 1.01)  # æ”¾å¤§åˆ°90%-100%å€é–“
        plt.legend()
        plt.title('Training Accuracy (Zoomed)')
        plt.grid(True)
        
        plt.tight_layout()
        plt.savefig('overfit_training_curves.png', dpi=300, bbox_inches='tight')
        print(f"âœ… è¨“ç·´æ›²ç·šå·²ä¿å­˜åˆ°: overfit_training_curves.png")
        plt.show()
    
    def save_model(self, filepath='perfect_cat_dog_model.pth'):
        """ä¿å­˜é”åˆ°100%æº–ç¢ºç‡çš„æ¨¡å‹"""
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'class_names': self.class_names,
            'model_architecture': 'resnet50_overfitted',
            'target_accuracy': self.target_accuracy,
            'training_type': 'overfitted_for_perfect_accuracy'
        }, filepath)
        print(f"ğŸ¯ å®Œç¾æ“¬åˆæ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")

def main():
    parser = argparse.ArgumentParser(description='è¨“ç·´100%æº–ç¢ºç‡çš„è²“ç‹—åˆ†é¡å™¨')
    parser.add_argument('--data-dir', type=str, default='kaggle_cats_vs_dogs_f',
                       help='æ•¸æ“šé›†è·¯å¾‘')
    parser.add_argument('--architecture', type=str, default='resnet50',
                       choices=['resnet18', 'resnet34', 'resnet50', 'resnet101'],
                       help='æ¨¡å‹æ¶æ§‹')
    parser.add_argument('--target-accuracy', type=float, default=1.0,
                       help='ç›®æ¨™è¨“ç·´æº–ç¢ºç‡ (0.0-1.0)')
    parser.add_argument('--max-epochs', type=int, default=200,
                       help='æœ€å¤§è¨“ç·´è¼ªæ•¸')
    
    args = parser.parse_args()
    
    # æª¢æŸ¥æ•¸æ“šè·¯å¾‘
    if not os.path.exists(args.data_dir):
        print(f"âŒ æ‰¾ä¸åˆ°æ•¸æ“šè·¯å¾‘: {args.data_dir}")
        return
    
    print("ğŸ¯ 100% è¨“ç·´æº–ç¢ºç‡å°ˆç”¨è¨“ç·´å™¨")
    print("=" * 50)
    print(f"ğŸ“‚ æ•¸æ“šè·¯å¾‘: {args.data_dir}")
    print(f"ğŸ—ï¸ æ¨¡å‹æ¶æ§‹: {args.architecture}")
    print(f"ğŸ¯ ç›®æ¨™æº–ç¢ºç‡: {args.target_accuracy*100:.1f}%")
    print(f"ğŸ”„ æœ€å¤§è¼ªæ•¸: {args.max_epochs}")
    
    # å‰µå»ºè¨“ç·´å™¨
    trainer = OverfitTrainer(args.data_dir, args.target_accuracy)
    
    # è¨“ç·´æµç¨‹
    trainer.load_data()
    trainer.build_model(args.architecture)
    trainer.train_to_perfection(args.max_epochs)
    trainer.save_model('perfect_cat_dog_model.pth')
    
    print("\nğŸ‰ è¨“ç·´å®Œæˆï¼")
    print("\nğŸ“‹ æ¥ä¸‹ä¾†ä½ å¯ä»¥:")
    print("1. ä½¿ç”¨ python predict.py --model perfect_cat_dog_model.pth --evaluate-train")
    print("2. é©—è­‰æ˜¯å¦é”åˆ° 100% è¨“ç·´æº–ç¢ºç‡")

if __name__ == '__main__':
    main()
