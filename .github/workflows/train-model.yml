name: Train Cat-Dog Classifier

on:
  push:
    # 只有這些分支推送時會觸發
    branches:
      - claude-resnet50-pre
      - claude-resnet50-no-pre-test
      - claude-resnet101-pre2
      - claude-resnet101-no-pre-test
      
  workflow_dispatch: {}   # 手動觸發
  schedule:
    - cron: '0 */6 * * *' # 每 6 小時（UTC）跑一次；會在預設分支觸發，但我們用 matrix 跑多分支

jobs:
  train:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        # 在這裡列出要自動跑的分支清單（排程 & 手動觸發時會全部跑一輪）
        branch:
        - claude-resnet50-pre
        - claude-resnet50-no-pre-test
        - claude-resnet101-pre2
        - claude-resnet101-no-pre-test

    steps:
    - name: Checkout target branch
      uses: actions/checkout@v4
      with:
        ref: ${{ matrix.branch }}

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.9'

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install kaggle gdown

    # 產生乾淨的 artifact 名稱（把分支名中的奇怪字元轉成底線）
    - name: Normalize branch name for artifact names
      id: names
      run: |
        SAFE="$(echo '${{ matrix.branch }}' | sed -e 's/[^A-Za-z0-9._-]/_/g')"
        echo "safe=$SAFE" >> $GITHUB_OUTPUT
        echo "CKPT_NAME=ckpt_${SAFE}" >> $GITHUB_ENV

    # 從先前 run 把相同分支的 checkpoint 抓回來（若沒有就忽略）
    - name: Download last checkpoint (if any)
      uses: dawidd6/action-download-artifact@v6
      with:
        name: ${{ env.CKPT_NAME }}
        path: ckpt_in
        search_artifacts: true
        if_no_artifact_found: ignore
        workflow_conclusion: completed

    - name: Build RESUME_ARG
      id: resume
      run: |
        if [ -f ckpt_in/checkpoint_latest.pth ]; then
          echo "resume=--resume ckpt_in/checkpoint_latest.pth" >> $GITHUB_OUTPUT
          echo "Found checkpoint_latest.pth, will resume."
        else
          echo "resume=" >> $GITHUB_OUTPUT
          echo "No checkpoint found, start fresh."
        fi

    # 從分支名自動決定要跑哪個 ResNet 架構
    - name: Extract architecture from branch name
      id: extract_arch
      run: |
        BR="${{ matrix.branch }}"
        if [[ "$BR" == *"resnet18"* ]]; then
          ARCH="resnet18"
        elif [[ "$BR" == *"resnet34"* ]]; then
          ARCH="resnet34"
        elif [[ "$BR" == *"resnet50"* ]]; then
          ARCH="resnet50"
        elif [[ "$BR" == *"resnet101"* ]]; then
          ARCH="resnet101"
        else
          ARCH="resnet18"  # fallback
        fi
        echo "arch=$ARCH" >> $GITHUB_OUTPUT
        echo "Detected architecture: $ARCH"

    # 下載資料集（你原本的 GDrive 版本）
    - name: Download dataset (GDrive)
      run: |
        echo "從 Google Drive 下載數據集..."

        gdown https://drive.google.com/uc?id=19QvyV00Zq6dwRY3hA8z_PyHB-naUUMB7 -O dataset.zip
        unzip -q dataset.zip -d file/
        
        gdown https://drive.google.com/uc?id=1PMfXfbvoqHRm0D3R4jsQ-xu4E63XXnvg -O file/train_32x32.mat
        gdown https://drive.google.com/uc?id=1JjprYjsCER8Upy9waLV_vH7Hyt8PYqbK -O file/test_32x32.mat
        echo "✅ 解壓完成"

    - name: Verify dataset structure
      run: |
        echo "檢查數據集結構..."
        ls -la file/train_32x32.mat || true
        ls -la file/test_32x32.mat || true
    
    - name: Train model (auto-stop before 6h)
      run: |
        echo "開始訓練模型（SVHN）..."
        python train_model.py \
          --data-dir file/ \
          --dataset svhn \
          --architecture ${{ steps.extract_arch.outputs.arch }} \
          --max-epochs 500 \
          --save-every 5 \
          --max-wall-min 330 \
          ${{ steps.resume.outputs.resume }}


    - name: Upload checkpoint for next run
      uses: actions/upload-artifact@v4
      with:
        name: ${{ env.CKPT_NAME }}    # 每個分支都有獨立的 artifact 名稱
        path: |
          checkpoint_latest.pth
          checkpoint_epoch*.pth
          checkpoint_best.pth
          TRAINING_COMPLETE.txt
          NEED_MORE.txt
        retention-days: 14


    - name: Prep SVHN val images (export a few PNGs)
      run: |
        python - <<'PY'
        from torchvision import datasets
        from PIL import Image
        import os
    
        root = 'file/'  # 這裡就是放 .mat 的資料夾
        os.makedirs('test_images', exist_ok=True)
        ds = datasets.SVHN(root=root, split='test', download=False)  # 用 .mat 載入
        N = max(0, len(ds))  # 匯出前 400 張就好，避免太多檔
        for i in range(N):
            img, label = ds[i]          # img 是 PIL.Image
            img.save(f'test_images/{label}_{i:05d}.png')
        print('Saved', N, 'val images to test_images/')
        PY
    
    - name: Test model predictions (val)
      if: ${{ hashFiles('number_model.pth') != '' }}
      run: |
        echo "測試模型預測（val）..."
        python predict.py --model number_model.pth --folder test_images/
    
    - name: Prep SVHN train images (export a few PNGs)
      run: |
        python - <<'PY'
        from torchvision import datasets
        from PIL import Image
        import os
    
        root = 'file/'
        os.makedirs('train_images', exist_ok=True)
        ds = datasets.SVHN(root=root, split='train', download=False)
        N = min(400, len(ds))
        for i in range(N):
            img, label = ds[i]
            img.save(f'train_images/{label}_{i:05d}.png')
        print('Saved', N, 'train images to train_images/')
        PY
    
    - name: Test model's train predictions
      if: ${{ hashFiles('number_model.pth') != '' }}
      run: |
        echo "測試模型預測（train）..."
        python predict_train.py --model number_model.pth --folder train_images/





    - name: Upload trained model
      if: ${{ hashFiles('number_model.pth') != '' }}
      uses: actions/upload-artifact@v4
      with:
        name: trained-cat-dog-model-${{ steps.names.outputs.safe }}
        path: |
          number_model.pth
          overfit_training_curves.png
        retention-days: 30
